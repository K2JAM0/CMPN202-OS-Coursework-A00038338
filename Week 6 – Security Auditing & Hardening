Week 6 — Phase 6: Performance Testing + File Systems + Network + Optimisation + Trade-offs
====================================================
TEST SETUP & METHODOLOGY

Performance testing was conducted remotely from the Fedora workstation
using SSH over the host-only network, as defined in Week 2.

Metrics were collected in three phases:
1) Baseline (idle)
2) Under load
3) After optimisation

All measurements were gathered using scripted SSH-based monitoring to
ensure consistency and repeatability.

═══════════════════════════════════════════════════════
FILE SYSTEM EXPLORATION (Lab)
ls -l /
ls -l /etc
ls -l /var
ls -l /home
sudo apt install tree -y
tree -L 2 /etc
stat /etc/passwd

![Filesystem structure](images/week6/week6-filesystem-tree.png)
*Figure 5: Directory hierarchy of /etc showing organised system configuration files.*

![passwd file metadata](images/week6/week6-passwd-stat.png)
*Figure 6: File metadata for /etc/passwd showing ownership, permissions, and timestamps.*

The Linux filesystem follows a hierarchical structure designed to separate
system binaries, configuration, variable data, and user files.

- / contains the root of the filesystem hierarchy and critical system directories.
- /etc stores system-wide configuration files, including user accounts and services.
- /var contains variable data such as logs, caches, and spool files that change frequently.
- /home stores user home directories and personal data.

The tree command was used to visualise the structure of /etc, confirming the
organisation of configuration files by service.

The stat command on /etc/passwd shows file ownership, permissions, and timestamps,
demonstrating how user account data is protected by standard UNIX permissions.

═══════════════════════════════════════════════════════
STORAGE PERFORMANCE (Lab)
sudo apt install sysstat iotop -y
iostat -x 2 5
sudo iotop -o

![Storage performance (iostat)](images/week6/week6-storage-iostat.png)
*Figure 7: Disk I/O performance on the Ubuntu server measured using `iostat -x`,
showing low disk utilisation, minimal I/O wait, and idle-state storage behaviour*
The results show the root disk (`sda`) operating with low utilisation and minimal
I/O wait, indicating no storage bottleneck during the baseline idle state.


# dd tests:
dd if=/dev/zero of=testfile bs=1M count=1024 oflag=direct
sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches'
dd if=testfile of=/dev/null bs=1M count=1024
rm testfile

# Sequential Disk Write Test (dd)
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.32085 s, 813 MB/s

The Sequential disk write test shows a strong average disk write of ~*813 MB/s*, This 
indicates that it is unlikely to be a limiting factor for the tested server workloads

═══════════════════════════════════════════════════════
NETWORK CONFIG + PERFORMANCE (Lab)
ip addr show
ip route show
ping -c 10 192.168.56.10
# iperf3:
# Server: iperf3 -s
# Workstation: iperf3 -c 192.168.56.10 -t 30

![Network configuration](images/week6/week6-network-config.png)
*Figure 2: Ubuntu server network configuration showing host-only interface with
IP address 192.168.56.10 used for administrative traffic.*

![Network latency test](images/week6/week6-network-latency.png)
*Figure 3: ICMP latency test from Fedora workstation to Ubuntu server over the host-only network,
showing low and consistent round-trip times.*

![Network throughput test](images/week6/week6-network-throughput.png)
*Figure 4: iperf3 TCP throughput test from the Fedora workstation to the Ubuntu server over the host-only network,
measuring sustained bandwidth and confirming stable network performance.*

| Test | Duration | Avg Throughput |
|----|----|----|
| iperf3 TCP | 30s | 2740 Mbps |
═══════════════════════════════════════════════════════
BASELINE PERFORMANCE TABLE (server idle)

![Baseline idle metrics](images/week6/week6-baseline-idle.png)
*Figure 1: Baseline (idle) system metrics collected over SSH from the Fedora workstation,
showing CPU, memory, disk usage, network interfaces, and socket summary before any workload is applied.*

| Metric | Baseline (Idle) |
|------|----------------|
| CPU usage | ~0–1% |
| Memory usage | ~376 MB |
| Disk usage | ~37% root filesystem |
| Active TCP connections | 9 |

═══════════════════════════════════════════════════════
APPLICATION LOAD TESTING (Apache)

![Apache under load](images/week6/week6-apache-load.png)
*Figure 8: Apache HTTP server under synthetic load using ApacheBench (ab),
showing increased CPU utilisation and active connections compared to baseline idle state.*

| Metric | Baseline | Under Load |
|------|--------|-----------|
| CPU usage | ~0–1% | ↑ during test |
| Memory usage | ~376 MB | ↑ |
| Disk usage | ~37% | ~37% |
| Active TCP connections | 9 | ↑ |



═══════════════════════════════════════════════════════
Optimisation #1: Apache MPM tuning (process/thread handling)

As shown in Figure 8, Apache was subjected to a synthetic workload using
ApacheBench with 1000 requests and a concurrency level of 50.
These measurements represent the pre-optimisation baseline under load
and are used as the reference point for the optimisation comparison below.

Before optimisation (baseline configuration):
Requests/sec: 4829.89
Time per request (mean): 10.352 ms
Transfer rate: 51624.18 KB/s

Commands used:
- apachectl -M | grep mpm
- ab -n 1000 -c 50 http://127.0.0.1/

After optimisation (MPM configuration adjusted):
Requests/sec: 4370.44
Time per request (mean): 11.441 ms
Transfer rate: 46713.33 KB/s

Improvement analysis:
Requests/sec decreased by ~9.5%
Latency increased by ~10.5%

This optimisation resulted in lower raw throughput and higher latency.
While performance decreased, the configuration prioritises safer and more
predictable behaviour under concurrent load.

Trade-offs:
- Reduced throughput in exchange for improved stability
- Higher per-request overhead due to worker/thread handling
- Configuration favours reliability over peak performance

Optimisation #2: Network throughput tuning using iperf3 validation

Baseline network throughput:
Average TCP throughput ([SUM] receiver): 27.4 Gbit/s

Commands used:
- iperf3 -s (server)
- iperf3 -c 192.168.56.10 -t 30 (workstation)

No configuration changes were applied to the network stack.
This optimisation validates that the host-only network configuration
is not a bottleneck for application traffic.

Improvement analysis:
Network throughput remained stable and consistently high.
No packet loss or instability was observed.

Trade-offs:
- Host-only networking provides isolation but limits external access
- High throughput is achieved at the cost of reduced flexibility

═══════════════════════════════════════════════════════
TRADE-OFF ANALYSIS (minimum 6 with quantitative data)
Trade-off #1: Apache performance vs stability  
Requests/sec decreased from 4829.89 to 4370.44 (~9.5% decrease)
in exchange for safer worker handling under concurrency.

Trade-off #2: Latency vs concurrency  
Mean request time increased from 10.352 ms to 11.441 ms (~10.5% increase)
when handling 50 concurrent connections.

Trade-off #3: Security vs usability (SSH hardening)  
Password authentication disabled, reducing attack surface but requiring
key-based access management.

Trade-off #4: Firewall restriction vs accessibility  
SSH access limited to 192.168.56.20 improves security but prevents
administration from other networks.

Trade-off #5: Automatic updates vs stability  
Unattended upgrades reduce vulnerability exposure but may introduce
service restarts after updates.

Trade-off #6: Host-only networking vs flexibility  
Network isolation improves security and predictability but prevents
external client access without reconfiguration.

═══════════════════════════════════════════════════════
VISUALISATIONS:

![ApacheBench Requests/sec chart](images/week6/chart-apache-reqs.png)
*Figure 9: ApacheBench Requests/sec (Before vs After) using the same test parameters.*

![Disk throughput chart](images/week6/chart-disk-dd.png)
*Figure 10: Disk write throughput measured with dd (direct write test).*

![iperf3 host-only throughput chart](images/week6/chart-network-iperf.png)
*Figure 11: iperf3 host-only throughput (Mbps). Value taken from the [SUM] receiver line.*

![iperf3 output evidence](images/week6/iperf3-proof.png)
*Figure 12: Fedora client iperf3 output used to extract the throughput value for the chart.*



═══════════════════════════════════════════════════════

